
## Concurrency

Two things happening at the same time


### Moore’s Law

While the number of transistors is still rising exponentially, the clock speed isn’t.
- we encounter a natural speed limit 
- Therefore, we start building CPU’s with multiple cores BUT the same speed

From the POV of the user, we have multiple / infinite CPUs, but in reality, we have few BUT we have a waiting queue

  
### Option 1 : Message Passing

- We build apps from many communicating processes, using message passing 
	- the processes have NO shared memory


Pros : if one process crashes, the rest are unaffected

Cons : high communication overheads (system calls), and expensive context switching

  

## Threads (option 2)

Threads are like processes except : 

- they all share an address space (in the same process)
    
- there are multiple threads in a process
    

  

Pros : they communicate through that address space

Cons : if one thread crashes, then the entire process (AND OTHER THREADS) fails

  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeF-RW0yYC7V_A8OmNZv--y3DvhE7rsypZ2VmAB5aTzfkQnFskHAefrYDGJoW0NRL2QNpR28Kv4ZF1hzpUBmc0AwFDDoozd5RbOJXqrepSgnX5dSrg3ZCbhrlAqLdR-MNeCS7oX3Q?key=Zxp6pP08T8TVtKzeAa5ztYV_)![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfNNHfq4189IVcyaWjOaYlJR21mjI_iZJKbQQl0DqaUEXZIG6l4VkUdOGNNRvDrUP4hfXjactIaJ-1FccN4lFQANLk3WADC66VRqXRMPgsklZLNCuvrSvwHBfpgDliXrnEUlZYu2g?key=Zxp6pP08T8TVtKzeAa5ztYV_)

  

## Processes vs. Threads

Processes : 

- provide separation (memory / data especially)
    
- better for coarse-grain interaction
    

  

Threads : 

- threads share memory (shared data)
    
- better for tight integration
    

  

### Shared data 

Pros : many threads can read/write it

Cons : idem, but this can lead to data races

  

### Data race

unexpected/unwanted access to shared data 

- this is a result of interleaving of thread executions
    

  

The program must be correct for all interleavings (example in lec3, slide 33)

  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdmqkvFxGS-IvDTl8_VN05tWL2iW9wzOS53wCXY3kZJadR70QoQ0lhSD4ZcbE1saMfYsdSl3ncNG78eUMQCc3xzUA8F_Mpg50lCZnFh5Eak4iXv_rY1RPZnmBT6ytPGdY7M5fVj?key=Zxp6pP08T8TVtKzeAa5ztYV_)

  

## Atomic operations

Know that a single line of C code is NOT always atomic 

- a = a + 1
	- load a from memory 
	- 0x195 mov 0x9cd4, %eax 
	- perform a + 1
	- 0x19a add $0x1, %eax
	- save the value for a 
	- 0x19d mov %eax, 0x9cd4


> [!warning] KEEP IN MIND
> `a++ ;` is NOT an atomic operation


## Non-determinism

Concurrency leads to non-deterministic results

- getting different results using the same inputs
    
- we should assume that the scheduler is malicious
    

  

## Approach to multithreading

1. divide work among multiple threads
    
2. share data
    

- Global variables and heap are shared
    
- NOT local and read-only variables
    
- Put the shared data access in a critical section
    

  

### Critical section

ex : we want 3 instructions to execute as an uninterruptible group

- we want them to be atomic
    

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeK7nC7IK57D104jWFBUoH6iT4Cf05NL207ylS0I70w-ZyYUfTYkvytPcImEun0fXwLwQ_7bAl9qk9vradqABIPgGE6Gp_XZKLML00t-g2v7LrlopO0bVXJQFTO9MjAc-Y9Xci5?key=Zxp6pP08T8TVtKzeAa5ztYV_)

We need mutual exclusion for critical sections

- if thread A is in critical section C, thread B can’t enter C
    
- it’s ok if other processes/threads do unrelated work
    

  

Why critical sections work : 

- no other threads can change the data
    
- we can avoid most problems
    

  
  

## Synchronization

Build higher-level synchronization primitives in the OS

- they ensure the correct ordering of instructions across threads
    
- we want to build them once and get it right 
    

  

### pthreads

it’s a thread API for C

- ``#include <pthread>``
    
- compile and link with ` -pthread `
    


`phtread_create()`

- create thread in thread
    


`pthread_exit()`

- terminate calling thread
    


`pthread_join()`

- join with a terminated thread
    
- waits for the thread specified by thread to exit
    
- if retval is not NULL, it copies the return value of of the target thread into the location pointed to by retval



### Fork join example 

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc9Pi_PcrI-m9-Up7kKhe7otcc7PylQBaJPGJNcTnRxyQKNgI36yI2TkwnbkH8Zlnp_QEL7ajgVgNzOsUwHKJV0deYPG_4WRg57mW4_9jWJlGaV6iYWT8aM2W5OMPJRx9DKRhE?key=Zxp6pP08T8TVtKzeAa5ztYV_) lec 3 - slide 68

- we could get AB but also BA
- we have no way of knowing, and we could get different results if we run it multiple times
  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfqPOKCMbbwDlo6PMy1QF_x8WIphtCOzjEtmZ9sRKOeYAVXmpxKIP3aPx4ag7AGgM8PwX9uCMFItGLtWEx8n8zXwoVoTHEfip__aBzRIU9dvu64q1s4g4cuKxVIex1Fluc2-oIgQw?key=Zxp6pP08T8TVtKzeAa5ztYV_) lect 3 - slide 69

- we can get any value between 1 000 000 and 2 000 000

  

## Locks

`pthread_mutex_lock(mutex)`

- if lock is held by another thread, block

- else 
	- acquire lock (you own it now)
	- proceed
  

`pthread_mutex_unlock(mutex)`
- release lock

Both take a pointer to a lock as parameter


### Lock example 
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdHgH0QCbInoTnyLbt7PDgBUf3SFyX_5NkxRrKPT98qjgpqDrUjdF8ziKiJafrjxeIjGOZctvY0ad3QVpamXIUTnysASH9U1xvX8Ip7tpEKdUfL_1T15rXVL6bcWSTgzSpvSI61?key=Zxp6pP08T8TVtKzeAa5ztYV_) lec 3 - slide 73

- now, we’re guaranteed to get 2 000 000 


## Deadlocks

threads are stuck waiting for blocked resources and no amount of retry (backoff) will help

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc_dOK7VmdiKmoOtooz5a6gM1HrZb-o6o2v3_KwkeOPNAhb1sY-yoBWnj9oc48riHDRuGmtO9nzdNYWOkgLDEWo5FfD0-Nw9K3dcnY2rVjz4v1wSo2AFsTGty8fsFDk1n5xXEMp_g?key=Zxp6pP08T8TVtKzeAa5ztYV_)

  
