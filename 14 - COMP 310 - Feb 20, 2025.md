
# [[Translation Lookaside Buffer (TLBs)]]

## Paging - problem
A problem with paging is the fact that we have to access the physical memory TWICE! 
1. To see the page table
2. To see the actual physical memory register

The <mark style="background: #D2B3FFA6;">slowest</mark> machine instruction is **loading/reading from memory**
- up to 200x slower than anything else

The problem is : if we make memory access twice as slow, then the whole program becomes twice as slow too! 
- Solution : implement a TLB!

## Introduction to TLBs

- They're **small**, **fast** hardware cache of popular (page num, frame num) maps
- It's a part of **MMU** (as seen [[13 - COMP 310 - Feb 18, 2025 |last class]])

If page num found in TLB : 
- use frame num from TLB
- abord mapping using page table
![[Screenshot 2025-02-20 at 10.25.46 AM.webp]]

Else : 
- perform mapping using page table
- insert (page num, frame num) in TLB
![[Screenshot 2025-02-20 at 10.26.07 AM.webp]]
^ then add (pageno, frameno) in TLB

## Why it's fast
We use **associative memory** (special hardware)
- better because regular memory does lookup by address

> [!Definition] Associative memory
> - lookup **by contents**
> - lookup **in parallel**
> - same concept as cache tags!

![[Screenshot 2025-02-20 at 10.29.16 AM.webp|578]]

## TLB size
Associative memory is VERY expensive!
- <mark style="background: #FF373791;">TLB is small (64 - 1024 entries)</mark>

We want the hit rate to be close to 100%

If the TLB is full, then we need to **replace entries**, but how?


## TLB hit rate and locality

<mark style="background: #5698FF9E;">Temporal locality</mark> : 
- instruction or data item that has been recently accessed will be likely re-accessed soon 

```c
int sum = 0 ;  
for (j=0; j<2; j++) {  
	for (i=0; i<10; i++)  
		sum+=a[i];  
}
```

![[Screenshot 2025-02-20 at 10.36.24 AM.webp]]


<mark style="background: #5698FF9E;">Spatial locality</mark> :
- if a program accesses memory at x, it will probably soon access memory *near* x

<mark style="background: #CACFD9A6;">example</mark> :
```c
int sum = 0 ;  
for (i=0; i<10; i++){  
	sum+=a[i];  
}
```

![[Screenshot 2025-02-20 at 10.34.57 AM.webp]]


# Process switching with TLBs

This might be a problem, because the TLB doesn't know what entry came from which process

![[Screenshot 2025-02-20 at 10.39.26 AM.webp]]

## Solution 1 
<mark style="background: #D2B3FFA6;">Just invalidate the TLB entries at every process switch!</mark>

<mark style="background: #76DD90A8;">Pros</mark> : 
- Easy

<mark style="background: #FF373791;">Cons</mark> : 
- Makes process switch expensive
- New process initially has 100% rate miss

![[Screenshot 2025-02-20 at 10.44.08 AM.webp]]


## Solution 2 
<mark style="background: #D2B3FFA6;">Add process identifier to the TLB entries</mark>
- Match = match on PID and match on pageno

<mark style="background: #76DD90A8;">Pros at process switch</mark> : 
- Nothing to do 
- Cheaper

<mark style="background: #FF373791;">Cons</mark> : 
- Makes TLB more complicated and expensive

![[Screenshot 2025-02-20 at 10.43.46 AM.webp]]

---

# Large address spaces
(In slide deck 7) 

<mark style="background: #76DD90A8;">Example</mark> : **64 bit virtual address space (64 bit CPU instructions)**
- 4kB pages → 12-bit page offset  
- Leaves 64 – 12 = 52 bits for pageno → 2^52 page table entries  
- Let’s say every page table entry 8B (true for x86 and aarch64)  
	- Page table size for one process = 8B * 2^52 PTEs = 2^55B  
	  = 2^5 x 2^50 = 32 Petabytes (More than main memory!)

- Why 4KB pages ?
	- it's a typical size of a page
	- Normally given as part of the problem statement, or you can deduce it with info given

- Why $2^{52}$ page table entries?
	- remember page size = 2$^{offset}$ bytes. Why?
		- every byte needs to have an address
		- we can represent 2$^{offset}$ addresses on offset bits
	- Page size = 4KB = ($2^2$ * $2^{10}$ B) = $2^{12}$ B  → Offset = 12

## Quiz on page table sizes:
1. PTEs are **2** bytes, and **32** possible virtual page numbers
	- 64 bytes (32 * 2)
2. PTEs are **2** bytes, virtual addrs are **24** bits, pages are **16** bytes
	- 4 bytes for offset (2^4 = 16)
	- 2^20 bytes for virtual page numbers (20 = 24 - 4)
	- 2^21 bytes = 2 MB (2^20 * 2)
3. PTEs are **4** bytes, virtual addrs are **32** bits, and pages are **2KB**
	- 8 MB (4 bytes * 2^(32 – log_2(2K)) = 4 * 2^21 bytes)

# Making page tables smaller
4. Make bigger pages
5. Segmentation + paging
6. Multi-level page tables

## Bigger pages
By doubling the size of a page, we can reduce the page table by a factor of 4!

<mark style="background: #76DD90A8;">Pros</mark> : 
- Easy
<mark style="background: #FF373791;">Cons</mark> : 
- Larger pages have higher internal fragmentation

## Segmentation + Paging
1. Divide the address space into segments (code, heap, stack)
	- Segments can be variable in length
2. Divide each segment into fixed-table sizes

Each virtual address is represented as such : 
![[Screenshot 2025-02-20 at 11.12.01 AM.webp]]

### Implementation 
- each segment has a page table
- each segment tracks base (physical address) and bounds of the page table for that address

## Quiz on segmentation & paging :

Slide 63 - lecture 7
![[Screenshot 2025-02-20 at 11.14.28 AM.webp]]

- each digit is equal to 4 bits (the address is in hexadecimal)